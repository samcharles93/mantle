date,time,optimisation,functions_touched,baseline_tps,final_tps,baseline_prompt_tps,final_prompt_tps,baseline_gen_tps,final_gen_tps,baseline_cudaMemcpy_api_total_ns,final_cudaMemcpy_api_total_ns,baseline_memcpy_h2d_count,final_memcpy_h2d_count,baseline_memcpy_d2h_count,final_memcpy_d2h_count,baseline_memcpy_h2d_total_ns,final_memcpy_h2d_total_ns,baseline_memcpy_d2h_total_ns,final_memcpy_d2h_total_ns,baseline_internal_h2d_mb,final_internal_h2d_mb,baseline_internal_d2h_mb,final_internal_d2h_mb,baseline_profile_ref,final_profile_ref,notes
2026-02-13,17:12:48,"Reintroduce device-state execution with host/device coherence tracking; defer host syncs via SyncHostState and keep residual x device-resident", "simd.DeviceStateOps(HostStateDirty,SyncHostState); simd.ForwardToken; simd.addResidual; cuda.Ops.BeginToken; cuda.Ops.EndToken; cuda.Ops.HostStateDirty; cuda.Ops.SyncHostState; cuda.Ops.DeviceAdd; cuda.Ops.DeviceRMSNorm; cuda.Ops.DeviceMatVec",3.6787456735016506,3.693527317117939,4.627078415921278,4.653966839390519,4.738487837930168,4.755109400993308,15636142791,8176258013,24002,12532,28011,12529,60928014,12696227,42677029,20043821,2491,2491,326,290,cuda_profile_20260213_170540,cuda_profile_20260213_171203,"Large memcpy reduction with stable output quality; remaining hotspot is quant_matvec_int8_blocks_f32_kernel"
2026-02-13,18:39:54,"Direct D2H into dst for quant MatVec on non-legacy sync path","Ops.matVecQuant, Ops.waitForResult",4.13705584085459,4.10935247230602,4.642039018940075,4.611530082154769,4.73002938143556,4.698311257192989,16503327403,16423496224,25062,24946,25060,24943,23974196,23568386,39663638,39652730,2639,2639,518,518,cuda_profile_20260213_183111,cuda_profile_20260213_183839,"Keep pinned staging only for MANTLE_CUDA_LEGACY_SYNC; remove extra host copy in default path"
2026-02-13,18:48:49,"Refactor int8 quant matvec reduction to warp-level two-stage sum","quant_matvec_int8_blocks_f32_kernel (softmax.cu)",4.119761142406719,4.109782624480658,4.642872931480845,4.618349644408206,4.707325489138569,4.697846513419597,16221561352,24620900178,25164,37667,24402,36960,195598635,167110549,38950449,59026299,2639,2639,518,518,cuda_profile_20260213_184544,cuda_profile_20260213_184735,"Replace full shared-memory tree reduction with warp reductions + 8-value shared partials"
2026-02-13,19:30:29,"Warp-per-row quant kernel + device-backed pre-norm matvec path in Attention/FFN","quant_matvec_int8_blocks_f32_kernel; cuda.Ops.DeviceRMSNorm/DeviceMatVec; simd.Attention; simd.FFN",4.109782624480658,20.02483567729354,4.618349644408206,21.58576298914024,4.697846513419597,23.036799683557305,24620900178,4819037993,37667,32460,36960,38903,167110549,123182937,59026299,61883353,2639,2575,518,518,cuda_profile_20260213_184735,cuda_profile_20260213_193008,"Map 1 warp to 1 row with multi-row blocks; mirror pre-norm outputs on device and prefer DeviceMatVec before host quant path"
2026-02-13,19:56:09,"Enable true mixed q8/f16 CUDA KV attention path and remove post-load cache-type override","cuda.Ops.AttentionInner; cuda.Ops.AttentionInnerProjection; cuda.Ops.StoreKV; cuda.Ops.ensureAttnCache; native.AttentionInnerMixedCacheF32; mantleCudaAttentionInnerMixedCacheF32; cmd.run load cache overrides",20.02483567729354,19.76058139481307,21.58576298914024,21.20304758564867,23.036799683557305,22.747491078622378,4819037993,4658048229,32460,37793,38903,37035,123182937,199240155,61883353,58590569,2575,2567,518,518,cuda_profile_20260213_193008,cuda_profile_20260213_195545,"q8_0 now executes attention_inner_mixed_cache_f32_kernel; fixed cgo pointer check for q8 scale upload; --ctk/--ctv no longer misleadingly reassigned after load"
2026-02-13,20:20:06,"Attempted attention_inner_mixed_cache_f32_kernel reduction/launch/q-cache tweaks; reverted to prior implementation after regressions","attention_inner_mixed_cache_f32_kernel (softmax.cu)",19.76058139481307,19.62026362371747,21.20304758564867,21.087199714454012,22.747491078622378,22.585413819267597,4658048229,4633186304,37793,37580,37035,37019,199240155,140340065,58590569,64188003,2567,2567,518,518,cuda_profile_20260213_195545,cuda_profile_20260213_201942,"Tried warp-level reduction, adaptive threads, and shared-q cache; none improved end-to-end TPS on this device/workload. Final code restored to previous stable mixed kernel."
2026-02-13,21:04:59,"Add shared-x quant matvec kernel with launch-time dispatch and vectorized full-block accumulation","quant_matvec_int8_blocks_f32_kernel; quant_matvec_int8_blocks_f32_xshared_kernel; mantleCudaQuantMatVecInt8BlocksF32",19.81688104554132,34.091591797431654,21.40689277020063,34.87365866318525,22.790342462832523,39.55231544965008,4668140187,2339520847,37793,37477,37035,37475,204794904,30886583,58600941,59417159,2567,2567,518,518,cuda_profile_20260213_204509,cuda_profile_20260213_210441,"Replaced dominant int8 matvec path with xshared variant for cols<=12k (48KB shared), forcing full relink to pick up .cu changes."
2026-02-13,21:24:45,"Redesign q4 quant matvec to warp-per-row with shared-x fast path and launch-time dispatch","quant_matvec_q4_f32_kernel; quant_matvec_q4_f32_xshared_kernel; mantleCudaQuantMatVecQ4F32",5.386434754337758,32.8264168620112,6.031843369847145,34.52920231609382,6.160861424859472,37.91996490744248,18623230574,6294777738,37406,37406,37236,37236,45564209,48747884,60046336,62427069,1483,1483,518,518,cuda_profile_20260213_211832,cuda_profile_20260213_212426,"Replace block-wide shared reduction with warp shuffle reduction; cache x in dynamic shared memory when cols fits 48KB."
2026-02-13,23:31:54,"Warp-reduce mixed attention and add register output fast path; remove explicit MatVecQKV stream sync on modern path","attention_inner_mixed_cache_f32_kernel; Ops.MatVecQKV",34.023038436266965,34.46188454103759,34.773976551544415,35.04388302110434,39.47643855241603,40.03575175115737,2359805859,2796597005,37580,38552,37019,37992,123244187,124705158,59058540,60821553,2567,2567,518,518,cuda_profile_20260213_232635,cuda_profile_20260213_233136,"Reduced attention kernel avg latency and removed cudaStreamSynchronize from QKV copy path (legacy env toggle preserved)."
2026-02-13,23:39:12,"Attempt vectorized char4/float4 full-block path in int8 xshared matvec","quant_matvec_int8_blocks_f32_xshared_kernel",34.46188454103759,31.67277650238064,35.04388302110434,31.872279700927525,40.03575175115737,36.84576632485867,2796597005,3035149305,38552,38434,37992,37873,124705158,121226931,60821553,60153953,2567,2567,518,518,cuda_profile_20260213_233136,cuda_profile_20260213_233854,"Regression (~34.46 -> ~31.67 TPS in profiled run); reverted to scalar-per-lane xshared loop."
2026-02-13,23:42:46,"Reuse device-resident x in QKV/FFN fast paths with on-device F32->F16 conversion","Ops.MatVecQKV; Ops.FFNBlock; Ops.deviceInputForVector",34.46188454103759,34.80994425435176,35.04388302110434,35.35521263299573,40.03575175115737,40.43829359169834,2796597005,2801703719,38552,34738,37992,37340,124705158,199410550,60821553,59420179,2567,2551,518,518,cuda_profile_20260213_233136,cuda_profile_20260213_234229,"When x is tracked on device (xPersist/normDev), avoid host upload and use device input directly; fallback to host path for BF16/unknown types."
